`Editor`: `윤은`

# **[📋논문 리뷰 1]** 

## GLIDE
###: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models

[논문](https://arxiv.org/pdf/2112.10741), [GITHUB](https://github.com/openai/glide-text2im), [DATASET](https://github.com/openai/clip) (CLIP의 데이터셋을 그대로 사용함.)

### 초록
CLIP guidance(DALL-E)와 classifier-free guidance(CLIP reranking)를 활용한 디퓨전 모델 테스트 결과, 인간 평가자가 느끼기에 후자가 캡션과 사진 간 유사돋가 높다고 평가함.

### INTRO
- 선행연구 분석
  - 의의: 자연어를 이용해 이미지를 편집함으로써 실제로 사용하기에 더 용이해짐 (사진의 미세한 조정 등)
  - 한계: 
    - 텍스트 조건부(text-conditional) 이미지 모델: 자유 형식의 텍스트 프롬프트에서 이미지를 합성할 수 있었으나 프롬프트에서 지시한 모든 것을 구현하지는 못합.
    - 조건이 없는(unconditional) 이미지 모델: 실제 사진과 구별할 수 없을 정도로 사실적인 이미지를 생성했음.
    
▶️ 이 둘을 조합하자!
  1. 자연어 설명을 조건으로 사용해, 텍스트 인코더를 사용하는 35억 파라미터 diffusion model을 만듦.
  2. 결과: CLIP과 classifier-free guidance를 비교
     - DALL-E보다 사실성 평가에서 87%, 캡션 유사성 평가에서 69% 더 선호되었음.
